{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import seaborn as sns\n",
    "import ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import detrend, savgol_filter, butter,sosfiltfilt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "import os     \n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f66218-4948-4527-9fa3-8b2a7f003c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['font.size']= 12\n",
    "plt.style.use(\"seaborn-colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e19b7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Introduction\n",
    "This notebook allows to analyse force-time data obtained from the Chiaro/Piuma nanoindenters from Optics 11 Life (https://www.optics11life.com/). \n",
    "It can analyse time signals acquired in displacement mode (keeping the piezo Z position constant), indentation mode (keeping the actual indentation constant using closed feedback) or load mode (keeping the force constant using closed feedback). However, it has been optimised to analyse data acquired in the first two modes, which allow to perform **stress relaxation** experiments. \n",
    "The notebook is divided into several sections that should be ran sequentially, and runs ipywidgets to make it more user friendly for non-programmers (i.e., the user is expected to interact with the notebook using buttons, sliders etc. without touching the code). \n",
    "\n",
    "The notebook reads data in the form of a convenient JSON file originating from the NanoPrepare software (time branch): https://github.com/CellMechLab/NanoPrepare/tree/time. The NanoPrepare software is open source and instructions for its use can be foud at: https://www.jove.com/t/63401/experimental-data-analysis-workflow-for-soft-matter. Essentially, NanoPrepare allows to load matrix scans and single indentations from performed experiments, clean the dataset and save cleaned data in a convenient single JSON file that is then read here. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790d703",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "## Functions\n",
    "This is the backend that contains functions used throughout the notebook. \n",
    "It needs to be ran, but not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387e405",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_curve(arrs):\n",
    "    \"\"\"Finds the average array from a list of arrays containing \n",
    "    arrays of different lengths.\"\"\"\n",
    "    lens = [len(i) for i in arrs]\n",
    "    arr = np.ma.empty((np.max(lens),len(arrs)))\n",
    "    arr.mask = True\n",
    "    for idx, l in enumerate(arrs):\n",
    "        arr[:len(l),idx] = l\n",
    "    return arr.mean(axis = -1), arr.std(axis=-1)\n",
    "    \n",
    "def find_CP(x,y,zerorange=900):\n",
    "    \"\"\"Finds the CP from F-Z curves by auto-thresholding data. \n",
    "    Algorithm writteb by Prof Massimo Vassalli and avilable\n",
    "    at the open source repository: https://github.com/CellMechLab/softmech\"\"\"\n",
    "    deg = 0 \n",
    "    worky = np.copy(y)\n",
    "    xtarget = np.min(x) + zerorange*1e-9\n",
    "    jtarget = np.argmin( np.abs(x-xtarget) )\n",
    "\n",
    "    #which direction?\n",
    "    if x[0]<x[-1]:\n",
    "        xlin = x[:jtarget]\n",
    "        ylin = worky[:jtarget]\n",
    "        m,q = np.polyfit(xlin,ylin,1)\n",
    "    else:\n",
    "        xlin = x[jtarget:]\n",
    "        ylin = worky[jtarget:]\n",
    "        m,q = np.polyfit(xlin,ylin,1)\n",
    "\n",
    "    worky = worky-m*x-q\n",
    "\n",
    "    differences = (worky[1:]+worky[:-1])/2\n",
    "    midpoints = np.array(list(set(differences)))\n",
    "    midpoints.sort()\n",
    "\n",
    "    crossings = []\n",
    "    for threshold in midpoints[midpoints>0]:\n",
    "        crossings.append( np.sum( np.bitwise_and( (worky[1:]>threshold),(worky[:-1]<threshold) )))\n",
    "    crossings=np.array(crossings)\n",
    "\n",
    "\n",
    "    inflection = midpoints[midpoints>0][np.where(crossings==1)[0][0]]\n",
    "    jcpguess = np.argmin( np.abs(differences-inflection) )+1\n",
    "\n",
    "    xcp = x[jcpguess]\n",
    "    ycp = y[jcpguess]\n",
    "    return [xcp, ycp]\n",
    "  \n",
    "def linear(x,a,b):\n",
    "    \"\"\"\"Linear function.\"\"\"\n",
    "    return a*x +b\n",
    "\n",
    "def sls_model(x,E_1,E_2,tau):\n",
    "    \"\"\"Standard linear solid (SLS) model. \n",
    "    Ref (DOI): 10.1039/c9sm01020c \"\"\"\n",
    "    C = (4.0 * np.sqrt(R) * delta_0**(3/2))/(3.0*(1-nu**2)) #Hertzian constant\n",
    "    E_t = E_2*np.exp(-x/tau)  #Relaxation modulus (One exponential)\n",
    "    return C * (E_1 + E_t)\n",
    "\n",
    "def prony_model(x,E_1,E_2,E_3,tau2,tau3):\n",
    "    \"\"\"Generalised model with two exponentials (Prony).\n",
    "    Ref (DOI): 10.1039/c9sm01020c\"\"\"\n",
    "    C = (4.0 * np.sqrt(R) * delta_0**(3/2))/(3.0*(1-nu**2)) #Hertzian constant\n",
    "    E_t = E_2*np.exp(-x/tau2) + E_3*np.exp(-x/tau3) #Relaxation modulus (Prony Series with two terms) \n",
    "    return C * (E_1+E_t)\n",
    "\n",
    "def do_fit(model,xdata,ydata,guess=None):\n",
    "    \"\"\"Fits data based on a given model.\"\"\"\n",
    "    xdata=np.asarray(xdata)\n",
    "    ydata=np.asarray(ydata)\n",
    "    popt, pcov = curve_fit(model,xdata,ydata,maxfev=10000,p0=guess)\n",
    "    xdata=np.linspace(min(xdata),max(xdata),1000)\n",
    "    return [xdata, model(xdata,*popt)]\n",
    "\n",
    "def linear_detrend(tdata,fdata,start_trend=5.0,end_trend=40.0):\n",
    "    \"\"\"Applies a linear detrend filter to F-t data in case of thermal drift.\"\"\"\n",
    "    #Isolate drifted signal\n",
    "    start = np.argmin((tdata-start_trend)**2) #end of fast relaxation\n",
    "    end = np.argmin((tdata-end_trend)**2) #end of signal \n",
    "    fdata_drift = fdata[start:end]\n",
    "    tdata_drift = tdata[start:end]\n",
    "    popt,pcov=curve_fit(linear,tdata_drift,fdata_drift)\n",
    "    time_all = np.linspace(min(tdata),max(tdata),len(tdata))\n",
    "    fmodel = linear(time_all,*popt)\n",
    "    de_drifted = fdata-fmodel\n",
    "    return de_drifted,popt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bc9da5-54c8-4f17-bbb5-7fcb7f01f3a5",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Input Data \n",
    "Below, input the path to the cleaned JSON file originating from the NanoPrepare complementary software. \n",
    "Also, input the spring constant (k) in N/m of the used cantilever. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282bf19",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirw=widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please enter the files directory',\n",
    "    description='Directory:',\n",
    "    disabled=False\n",
    ")\n",
    "display(dirw)\n",
    "\n",
    "cantilever_k = widgets.FloatText(\n",
    "    value=0.5,\n",
    "    description='k (N/m):',\n",
    "    disabled=False\n",
    ")\n",
    "display(cantilever_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f27d1fdf-b5b2-4413-963e-164ff04bb11e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Find initial indentation depth \n",
    "If measurements are performed in displacement (Z) control, the indentation depth will increase as the force relaxes (indentation = Z - F/k after the contact point; where Z is constant and F decays). This drift is generally negligible but can be corrected for by taking the average of the indentation over time after the maximum force is reached (https://doi.org/10.1115/1.3194752) - which is not addressed here.  If measurements are performed in indentation control mode, the indentation is kept constant at the initial indentation throughout the duration of the experiment; and no correction is needed.  \n",
    "Below, an overview of the dataset is given: the first graph shows force v displacement ($F-Z$); the second graph shows force v indentation ($F-\\delta$) data; where $\\delta$ is calculated by finding the contact point, which can be tweaked with the \"set_to_zero\" slider. The third graph shows the evolution of the indentation in time after the contact point for individual curves (black) and on average (red). The last graph shows the histogram of the initial indentation depth, which can be compared to the final indentation depth on graph 3 (red)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dcc3b75-242c-44d8-bddd-889636f1ab08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "k = cantilever_k.value #N/m\n",
    "f = open(dirw.value)\n",
    "data = json.load(f)\n",
    "indentation = []\n",
    "time = []\n",
    "average_ind = []\n",
    "def zero_plot(set_to_zero=900):\n",
    "    min_ind=[] #the minimum indentation (initial indentation)\n",
    "    fig,ax=plt.subplots(1,4,figsize=(12,3))\n",
    "    for i in range(len(data['curves'])):\n",
    "        for_force = np.array(data['curves'][i]['data']['F']) #for = forward segment, units of loaded data are N\n",
    "        for_Z = np.array(data['curves'][i]['data']['Z'])  #for = forward segment, units of laoded data are m\n",
    "        raw_time = np.array(data['curves'][i]['raw_data']['raw_time']) #s\n",
    "        raw_force = np.array(data['curves'][i]['raw_data']['raw_force'])* 1e-9 #units are in nN\n",
    "        raw_Z = np.array(data['curves'][i]['raw_data']['raw_z']) *1e-9 # #multiply by 1e-9 because units of loaded data are nm\n",
    "\n",
    "        #if the for_force signal exists: \n",
    "        if for_force is not None and len(for_force)>0: \n",
    "            for_off = for_force[0]\n",
    "            raw_force_off = raw_force[0]\n",
    "            if for_off <0: \n",
    "                for_force = for_force-for_off\n",
    "                raw_force = raw_force-raw_force_off\n",
    "\n",
    "            #find the CP \n",
    "            z0,f0 = find_CP(for_Z,for_force,set_to_zero)\n",
    "\n",
    "            #forward segment \n",
    "            ind = for_Z[np.argmin((for_Z-z0)**2)::]-z0 #Note that ind is miselading as this is actually only z normalised to the CP! \n",
    "            f_ind=for_force[np.argmin((for_force-f0)**2)::]-f0\n",
    "\n",
    "            #Whole signal as a function of time \n",
    "            Z_from_CP = raw_Z[np.argmin((for_Z-z0)**2)::]-z0 #Z from CP as a function of time\n",
    "            f_from_CP = raw_force[np.argmin((for_force-f0)**2)::]-f0 #F from CP as a function of time\n",
    "            t_from_CP = raw_time[np.argmin((for_force-f0)**2)::] #time from CP\n",
    "\n",
    "            ax[0].plot(for_Z-z0,for_force, lw=0.1,c='k')\n",
    "\n",
    "            if len(ind)==len(f_ind):\n",
    "                #sometimes ind and f_ind do not have the same length (probably something due to cp algorithm)\n",
    "                ind_from_CP = Z_from_CP - f_from_CP/k #z-F/k, so it should increase if F is relaxing and Z is constant \n",
    "                indentation.append(ind_from_CP) \n",
    "                time.append(t_from_CP)\n",
    "                ax[1].plot(ind-f_ind/k,f_ind, lw=0.1,c='k') #forward segment\n",
    "                ax[2].plot(t_from_CP,ind_from_CP,lw=0.05,c='k') #whole signal\n",
    "                min_ind.append(max(ind-f_ind/k)) #indentation is taken from forward segment\n",
    "        \n",
    "        if len(time)>0:\n",
    "            t_av, _ = average_curve(time)\n",
    "            ind_av,ind_av_err = average_curve(indentation)\n",
    "    \n",
    "    print(f'average initial indentation (m): {(np.mean(min_ind))}')\n",
    "    \n",
    "    average_ind.append(np.mean(min_ind)) #store in final file (*assume indentation does not change*)\n",
    "    \n",
    "    ax[2].plot(t_av,ind_av,color='r', lw=1)\n",
    "    ax[3]=sns.histplot(min_ind,kde='true',alpha=0.5)\n",
    "    ax[0].set_xlabel('$z-z_0$ (m)')\n",
    "    ax[1].set_xlabel('$\\delta$ (m)')\n",
    "    ax[2].set_xlabel('t (s)')\n",
    "    ax[0].set_ylabel('$F$ (N)')\n",
    "    ax[1].set_ylabel('$F$ (N)')\n",
    "    ax[2].set_ylabel('$\\delta$ (m)')\n",
    "    ax[3].set_title('initial $\\delta$ (m)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "plotzerow=widgets.interactive(zero_plot,set_to_zero=(500,2000,0.5))\n",
    "display(plotzerow)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d268de",
   "metadata": {},
   "source": [
    "## Screening \n",
    "The plot below allows to select four thresholds for removing bad time data and aligning time data. This section is used only to selct the thresholds; the actual data is thresholded in the next section (**Adjusting**) if the \"Threshold\" checkbox is ticked. The data can be thresholded based on the following thresholds: \n",
    "\n",
    "1. tmin (s): the time under which the maximum force should occur. Any curve whose maximum force occurs after this time is discarded from the analysis. \n",
    "2. tmax (s): the maximum time one wants to display and analyse the data for. This is used to essentially remove the ramping down of the stress relaxation curve. Alla data points after this time are discarded.\n",
    "3. fmin (nN): the minimum acceptable value for the maximum (peak) force. Any curve whose maximum force is smaller than fmin will be discarded.\n",
    "4. fmax (nN): the maximum acceptable value for the maximum (peak) force. Any curve whose maximum force is greater than fmax will be discarded.\n",
    "\n",
    "tip: adjust the sliders by typing the approximate value for the variable in the box next to the slider and click enter on your keyboard. Just sliding will update the plot for each value the slider passes through, resulting in a laggy visual update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dirw.value)\n",
    "data = json.load(f)\n",
    "def first_plot(tmin=0.5,tmax=30.0,fmin=0.0,fmax=50.0):\n",
    "    fig,ax=plt.subplots(1,1,figsize=(10,5))\n",
    "    tall = []\n",
    "    fall = []\n",
    "    for i in range(len(data['curves'])):\n",
    "        raw_time = np.array(data['curves'][i]['raw_data']['raw_time'])\n",
    "        raw_force = np.array(data['curves'][i]['raw_data']['raw_force'])\n",
    "\n",
    "        #Offset force-time curves \n",
    "        off = raw_force[0] #first point\n",
    "        #if forst point is negative, align\n",
    "        if off <0: \n",
    "            raw_force = raw_force-off\n",
    "    \n",
    "        ax.plot(raw_time,raw_force,alpha=1,lw=0.1,c='k')\n",
    "        ax.axhline(fmin,c=\"salmon\",lw=1)\n",
    "        ax.axhline(fmax,c=\"salmon\",lw=1)\n",
    "        ax.axvline(tmax,lw=1)\n",
    "        ax.axvline(tmin,lw=1)\n",
    "    ax.set_xlabel('$t$ (s)')\n",
    "    ax.set_ylabel('$F$ (nN)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "plot1w=widgets.interactive(first_plot,tmin=(0.0,50.0,0.5), tmax=(0.0,120.0,0.5),fmin=(0.0,1500.0,0.1),fmax=(0.0,4000.0,0.1))\n",
    "display(plot1w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5000cc8",
   "metadata": {},
   "source": [
    "## Adjusting\n",
    "Now click the \"Threshold\" checkbox below to apply the above-specified thresholds to the data.\n",
    "\n",
    "Given the above specified thresholds, the code below finds the maximum force and corresponding time and aligns this value to 0. All curves should now start from t=0. Note that the maximum time displayed will be different from the one selected above as curves are shifted by the time at which the maximum force occurs (however relative time interval is preserved)!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdw=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Threshold data',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(thresholdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf7ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Widget parameters (Global thresholds)\n",
    "t_min=plot1w.kwargs[\"tmin\"] #time under which max force should occur (s)\n",
    "t_max=plot1w.kwargs[\"tmax\"] #max time to display and analyse data for (s)\n",
    "f_min=plot1w.kwargs[\"fmin\"] #The minium acceptable value for the max force (uN)\n",
    "f_max = plot1w.kwargs[\"fmax\"]#The maximum acceptable value for the max force (uN)\n",
    "\n",
    "#Variables to store\n",
    "tall = []\n",
    "fall = []\n",
    "indall = []\n",
    "tallind = []\n",
    "fnormall=[]\n",
    "interval = []\n",
    "\n",
    "fig,ax = plt.subplots(1,1,figsize=(6,3))\n",
    "for i in range(len(data['curves'])):\n",
    "    raw_time = np.array(data['curves'][i]['raw_data']['raw_time']) #s\n",
    "    raw_force = np.array(data['curves'][i]['raw_data']['raw_force']) #nN\n",
    "    raw_Z = np.array(data['curves'][i]['raw_data']['raw_z']) *1e-9 # #multiply by 1e-9 because units of loaded data are nm\n",
    "\n",
    "    raw_force_off = raw_force[0]\n",
    "    if raw_force_off <0: \n",
    "        raw_force = raw_force-raw_force_off\n",
    "\n",
    "    #Clean data based on user-selected thresholds\n",
    "    #NB: to be applied on raw data \n",
    "    fmax = max(raw_force)\n",
    "    imaxf = np.argmin((raw_force-fmax)**2)\n",
    "    if thresholdw.value is True:\n",
    "        if (fmax > f_max) or (fmax < f_min) or raw_time[imaxf] > t_min:\n",
    "            continue \n",
    "\n",
    "    #Align data to 0 and slice to user-selcted max time\n",
    "    itmax =np.argmin((raw_time-t_max)**2)\n",
    "    t=raw_time[imaxf:itmax]-raw_time[imaxf]\n",
    "    f=raw_force[imaxf:itmax]\n",
    "    #Normalise force and append\n",
    "    fnorm=f/max(f) \n",
    "    tall.append(t)\n",
    "    fall.append(f)\n",
    "    fnormall.append(fnorm)\n",
    "\n",
    "#Find and plot the average curve\n",
    "t_av,_=average_curve(tall) #time\n",
    "f_av, f_err = average_curve(fall) #force and its error\n",
    "f_av_norm=f_av/max(f_av) #normalised average force ( NB #this one can be affected by jump at the end due to averaging)\n",
    "_,f_err_norm=average_curve(fnormall) #average normalised force error \n",
    "ax.plot(t_av,f_av,lw=1,ls='-',alpha=1) \n",
    "ax.set_xlabel('$t$ (s)')\n",
    "ax.set_ylabel('$F$ (nN)')\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3897a04f-99c5-4cf6-8816-36761de4a307",
   "metadata": {},
   "source": [
    "Due to the nature of the algorithm employed to find the average curve, the last portion of the curve contains numerical noise.This can be removed using the following slider, to be placed just before the noise starts: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902286e8-8be4-4dbf-bf73-e23696c04e03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cut_average_curve(cut_time=50.0):\n",
    "    fig, ax = plt.subplots(1,1,figsize = (6,3))\n",
    "    ax.plot(t_av,f_av)\n",
    "    ax.axvline(cut_time,color='r')\n",
    "    ax.set_xlabel('Time (s)')\n",
    "    ax.set_ylabel('Force (nN)')\n",
    "    fig.tight_layout()\n",
    "plot2w=widgets.interactive(cut_average_curve,cut_time=(0.0,200.0,0.1))\n",
    "display(plot2w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17adea19-4171-4474-8442-640e788439e1",
   "metadata": {},
   "source": [
    "Now that the cutting threshold has been selected, run the cell below to display the final average curve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f198350c-049e-4672-aa14-725212411708",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_cut = plot2w.kwargs['cut_time']\n",
    "i_t_cut = np.argmin((t_av-t_cut)**2)\n",
    "t_av = t_av[:i_t_cut]\n",
    "f_av=f_av[:i_t_cut]\n",
    "f_err=f_err[:i_t_cut]\n",
    "f_av_norm=f_av/max(f_av) #re calculate after cutting\n",
    "f_err_norm=f_err_norm[:i_t_cut]\n",
    "fig, ax = plt.subplots(1,1,figsize = (10,5))\n",
    "ax.plot(t_av,f_av)\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Force (nN)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3ef6e-0c89-4fa5-a075-9d76a6c46835",
   "metadata": {},
   "source": [
    "If the average curve has an upwards trend (temperature drift), detrend data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d203b13-edd9-4d27-9b67-2012094a9904",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "detrendw=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Detrend data',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(detrendw)\n",
    "detrend_range = widgets.FloatRangeSlider(\n",
    "    value=[10.0, 60.0],\n",
    "    min=0,\n",
    "    max=50.0,\n",
    "    step=0.1,\n",
    "    description='Detrend Range:',\n",
    "    disabled=False,\n",
    "    continuous_update=False,\n",
    "    orientation='horizontal',\n",
    "    readout=True,\n",
    "    readout_format='.1f',\n",
    ")\n",
    "display(detrend_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b459afe-d583-4857-91a1-694c936a7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(6,2))\n",
    "if detrendw.value is True: \n",
    "    #average curve (absolute)\n",
    "    f_av_detrended,optd = linear_detrend(t_av,f_av,start_trend=detrend_range.value[0],end_trend=detrend_range.value[1]) \n",
    "    f_av_detrended = f_av_detrended+optd[1] #add back y intercept for correct f scaling\n",
    "    f_av = f_av_detrended\n",
    "    f_av_norm = f_av/max(f_av)\n",
    "    #error (absolute)\n",
    "    f_err_detrended,optd = linear_detrend(t_av,f_err,start_trend=detrend_range.value[0],end_trend=detrend_range.value[1]) \n",
    "    f_err_detrended = f_err_detrended+optd[1]\n",
    "    f_err=f_err_detrended\n",
    "    #error (from normalised curves)\n",
    "    f_err_detrended_norm,optd = linear_detrend(t_av,f_err_norm,start_trend=detrend_range.value[0],end_trend=detrend_range.value[1]) \n",
    "    f_err_detrended_norm = f_err_detrended_norm+optd[1]\n",
    "    f_err_norm=f_err_detrended_norm\n",
    "    \n",
    "axs[0].plot(t_av,f_av)\n",
    "axs[1].plot(t_av,f_av_norm)\n",
    "axs[0].set_title(\"Data\")\n",
    "axs[1].set_title(\"Normalised Data\")\n",
    "axs[0].set_xlabel(\"Time (s)\")\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "axs[0].set_ylabel(\"Force (nN)\")\n",
    "axs[1].set_ylabel(\"Norm. Force\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b885c35-6b94-4e4a-bcde-5ee7e83688d4",
   "metadata": {},
   "source": [
    "## Fitting data\n",
    "Fit average curve with relaxation model. This can be a Standard linear solid (SLS) or Prony series; i.e. a generalised maxwell model with two relaxation times, see for example https://pubs.rsc.org/en/content/articlelanding/2020/sm/c9sm01020c or https://pubs.rsc.org/en/content/articlelanding/2020/bm/c9bm01339c).\n",
    "The SLS model has 3 fitting parameters ($E_1$, the long term elastic modulus - $E_2$, the relaxation modulus - and its associated time constant, $\\tau_2$).\n",
    "The prony series model has 4 fitting parameters ($E_1$, the long term elastic modulus - $E_2$ and $E_3$, the relaxation moduli - and their associated time constants, $\\tau_2$ and $\\tau_3$).\n",
    "The user needs to enter the Poisson's ratio, the tip radius and the approximate constant indentation depth (which is printed in the cell \"find initial indentation depth\"); as Hertzian contact is still assumed. After, the user is prompted with what model to fit the average curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012701f-4a00-4084-bab3-b95c6ecf2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson = widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Poisson\\'s:',\n",
    "    disabled=False\n",
    ")\n",
    "display(poisson)\n",
    "\n",
    "radius = widgets.BoundedFloatText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=250,\n",
    "    step=0.5,\n",
    "    description='$R$ (um):',\n",
    "    disabled=False\n",
    ")\n",
    "display(radius)\n",
    "\n",
    "#delta_0 does not impact on the estimation of the relaxation times\n",
    "ind_0 = widgets.BoundedFloatText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=250,\n",
    "    step=0.5,\n",
    "    description='$\\delta_0$ (um):',\n",
    "    disabled=False\n",
    ")\n",
    "display(ind_0)\n",
    "\n",
    "chosen_model = widgets.Dropdown(\n",
    "    options=['SLS', 'Prony'],\n",
    "    value='Prony',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cd860-c71c-4681-bd45-0c427439b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = poisson.value\n",
    "R = radius.value\n",
    "delta_0 = ind_0.value\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,2))\n",
    "if chosen_model.value==\"Prony\":\n",
    "    model_name = \"Prony\"\n",
    "    seed = [f_av_norm[-1],(f_av_norm[-1]+f_av_norm[0]),(f_av_norm[-1]+f_av_norm[0]),0.1,10.0]\n",
    "    seed_raw = [f_av[-1],(f_av[-1]+f_av[0]),(f_av[-1]+f_av[0]),0.1,10.0]\n",
    "    \n",
    "    popt,pcov = curve_fit(prony_model,t_av,f_av_norm,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"\n",
    "    popt_raw,pcov_raw = curve_fit(prony_model,t_av,f_av,p0=seed_raw,maxfev=100000) #method='trf', #loss=\"soft_l1\"\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    perr_raw = np.sqrt(np.diag(pcov_raw))\n",
    "    \n",
    "    ax.plot(t_av,f_av_norm,lw=4,label=\"Raw data\")\n",
    "    ax.plot(t_av,prony_model(t_av,*popt),'--',c='r',lw=2,label=model_name +\" Model\")\n",
    "    \n",
    "    norm_model=prony_model(t_av,*popt)\n",
    "    raw_model=prony_model(t_av,*popt_raw)\n",
    "    \n",
    "if chosen_model.value==\"SLS\":\n",
    "    model_name = \"SLS\"\n",
    "    seed = [f_av_norm[-1],(f_av_norm[-1]+f_av_norm[0]),10.0]\n",
    "    seed_raw = [f_av[-1],(f_av[-1]+f_av[0]),10.0]\n",
    "    \n",
    "    popt,pcov = curve_fit(sls_model,t_av,f_av_norm,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"s\n",
    "    popt_raw,pcov_raw = curve_fit(sls_model,t_av,f_av,p0=seed_raw,maxfev=100000)\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    perr_raw = np.sqrt(np.diag(pcov_raw))\n",
    "\n",
    "    ax.plot(t_av,f_av_norm,lw=4,label=\"Raw data\")\n",
    "    ax.plot(t_av,sls_model(t_av,*popt),'--',c='r',lw=2,label=model_name+\" Model\")\n",
    "    norm_model=sls_model(t_av,*popt)\n",
    "    raw_model=sls_model(t_av,*popt_raw)\n",
    "\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Norm Force\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ced0ad-7b73-4467-8a01-ea89ca54e19c",
   "metadata": {},
   "source": [
    "Final plot to save for representative purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d4589-c84c-4808-b25d-efb34300b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(4,2.5))\n",
    "ax.plot(t_av,f_av_norm,label=\"Average Data\")\n",
    "ax.fill_between(t_av,f_av_norm-0.5*f_err_norm,f_av_norm+0.5*f_err_norm,alpha=0.3,label=\"1SD\")\n",
    "ax.plot(t_av,norm_model,'--',c='r',lw=1,label=model_name+\" Model\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Norm. Force\")\n",
    "plt.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9d138c-4e9d-4d06-94e3-6b87ab6f578e",
   "metadata": {},
   "source": [
    "## Calculating energy dissipation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0c2609-8f19-4d35-b105-fb507fe65415",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(5,2))\n",
    "ax.axhline(1,xmin=0.05,xmax=0.95,color='k',lw=1,label='Perfectly elastic',ls='--')\n",
    "ax.plot(t_av,f_av_norm,label=\"Average Data\")\n",
    "f_err_min = f_av_norm-0.5*f_err_norm\n",
    "f_err_max = f_av_norm+0.5*f_err_norm\n",
    "ax.fill_between(t_av,f_err_min,f_err_max,alpha=0.5,label=\"1SD\")\n",
    "ax.fill_between(t_av,f_av_norm[0],f_av_norm,alpha=0.3)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Norm. Force\")\n",
    "plt.legend(bbox_to_anchor=(1, 1.04))\n",
    "fig.tight_layout()\n",
    "av_en_dissipated = f_av_norm[0]-f_av_norm[-1]\n",
    "max_en_dissipated = f_av_norm[0]-f_err_min[-1]\n",
    "min_en_dissipated = f_av_norm[0]-f_err_max[-1]\n",
    "sd = (f_err_max[-1] - f_err_min[-1])\n",
    "print(min_en_dissipated*100)\n",
    "print(av_en_dissipated*100)\n",
    "print(max_en_dissipated*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c7e44a-fb0b-4ea9-98fe-ae432984130d",
   "metadata": {},
   "source": [
    "## Relaxation time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38f33ed-1695-4243-af5b-ae1a8fa4ee05",
   "metadata": {},
   "outputs": [],
   "source": [
    "relaxation_timew=widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    disabled=False\n",
    ")\n",
    "boxw=widgets.HBox([widgets.Label(value=\"Enter stress value for which relaxation time is calculated:\"), relaxation_timew])\n",
    "display(boxw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1171158b-df40-4eaa-9516-096b814f5193",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract time at which force reaches % of original value (specified above)\n",
    "F_TARGET=relaxation_timew.value*(max(f_av_norm)) \n",
    "f_err_min = f_av_norm-0.5*f_err_norm\n",
    "f_err_max = f_av_norm+0.5*f_err_norm\n",
    "force_range = [f_av_norm, f_err_min, f_err_max]\n",
    "relaxation_time_range = []\n",
    "force_index_range = []\n",
    "for i, f in enumerate (force_range): \n",
    "    i_fclose = np.argmin((f-F_TARGET)**2) \n",
    "    t_target = t_av[i_fclose]\n",
    "    relaxation_time_range.append(t_target)\n",
    "    force_index_range.append(i_fclose)\n",
    "avg_relaxation_time = np.mean(relaxation_time_range)\n",
    "std_relaxation_time = np.std(relaxation_time_range)\n",
    "plt.plot(t_av,f_av_norm)\n",
    "plt.plot(relaxation_time_range[0],f_av_norm[force_index_range[0]], 'o',c='r')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4ba5a-04fb-410f-ad52-08cfe77ae7f0",
   "metadata": {},
   "source": [
    " ## Saving data\n",
    " The cell below saves the data from the average curve in a .tsv file, together with the fitted model and best model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be82057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savingfolderw=widgets.Text(\n",
    "    placeholder='Output folder',\n",
    "    disabled=False\n",
    ")\n",
    "boxw1=widgets.HBox([widgets.Label(value=\"Output Folder\"), savingfolderw])\n",
    "display(boxw1)\n",
    "\n",
    "samplenamew=widgets.Text(\n",
    "    placeholder='Please enter the sample name',\n",
    "    disabled=False\n",
    ")\n",
    "boxw2=widgets.HBox([widgets.Label(value=\"Sample Name\"), samplenamew])\n",
    "display(boxw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798b5e1-a51b-43bd-a0d2-6f59885456f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=savingfolderw.value+\"/\"+samplenamew.value +\".tsv\"\n",
    "with open(fname,\"w\") as f: \n",
    "    f.write(\"Exported stress relaxation analysis \\n\")\n",
    "    f.write(\"Sample Name: {} \\n\".format(samplenamew.value))\n",
    "    f.write(\"Time for Energy Dissipation (s): %.2f \\n\"%(t_av[-1]))\n",
    "    f.write(\"Average Energy Dissipated: {} \\n\".format(av_en_dissipated*100.0))\n",
    "    f.write(\"SD Energy Dissipated: {} \\n\".format(sd*100.0))\n",
    "    f.write(\"Stress value for relaxation time: {} \\n\".format(F_TARGET))\n",
    "    f.write(\"Average time to reach stress value: {} \\n\".format(avg_relaxation_time))\n",
    "    f.write(\"std time to reach stress value: {} \\n\".format(std_relaxation_time))\n",
    "    # f.write(\"Max Energy Dissipated: {} \\n\".format(max_en_dissipated*100.0))\n",
    "    # f.write(\"Min Energy Dissipated: {} \\n\".format(min_en_dissipated*100.0))\n",
    "    f.write(\"Number of points: {}\\n\".format(len(data['curves'])))\n",
    "    f.write(\"Initial indentation (um) {} \\n\".format(average_ind[0]*1e6))\n",
    "    f.write(\"Bead Radius (um) {} \\n\".format(radius.value))\n",
    "    f.write(\"Fitted model: {} \\n\".format(model_name))\n",
    "    if model_name == \"Prony\":\n",
    "        f.write(\"Model E_inf (nN/um2) {} pm {} \\n\".format(popt_raw[0],perr_raw[0]))\n",
    "        f.write(\"Model E_rel_1 (nN/um2) {} pm {} \\n\".format(popt_raw[1],perr_raw[1]))\n",
    "        f.write(\"Model E_rel_2 (nN/um2) {} pm {} \\n\".format(popt_raw[2],perr_raw[2]))\n",
    "        f.write(\"Model tau_rel_1 (s) {} pm {} \\n\".format(popt[3],perr[3]))\n",
    "        f.write(\"Model tau_rel_2 (s) {} pm {} \\n\".format(popt[4],perr[4]))\n",
    "    if model_name ==\"SLS\":\n",
    "        f.write(\"Model E_inf (nN/um2) {} pm {} \\n\".format(popt_raw[0],perr_raw[0]))\n",
    "        f.write(\"Model E_rel (nN/um2) {} pm {} \\n\".format(popt_raw[1],perr_raw[1]))\n",
    "        f.write(\"Model tau_rel (s) {} pm {} \\n\".format(popt[2],perr[2])) #does not matter if using normalised signal or not\n",
    "    f.write('Avg time [s] \\t Avg Norm Force \\t Error Norm Force \\t Avg Force (nN) \\t Error Force (nN) \\t Normalised Model \\t Raw Model (nN) \\n')\n",
    "    for x in zip(*[t_av,f_av_norm, f_err_norm, f_av, f_err, norm_model,raw_model]):\n",
    "                 f.write(\"{0}\\t{1}\\t{2}\\t{3}\\t{4}\\t{5}\\t{6}\\n\".format(*x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa71156-bf31-4bce-8b8a-892c277f926b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "84b25d0415491253f03f694f57af598572a98abd3b82a154133d6b656667b885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
