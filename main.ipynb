{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01a785e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import ipywidgets\n",
    "import ipywidgets as widgets\n",
    "from scipy.signal import detrend, savgol_filter, butter,sosfiltfilt\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.interpolate import interp1d\n",
    "import os     \n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f66218-4948-4527-9fa3-8b2a7f003c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plots parameters\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size']= 15\n",
    "plt.style.use(\"seaborn-colorblind\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6e19b7",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook allows to analyse stress relaxation data obtained from the Chiaro/Piuma/ nanoindenters from Optics 11 Life. It is divided into several sections that should be ran in order. The notebook runs ipywidgets to make it more user friendly for non-programmers.\n",
    "This is a work in progress and the notebook is at a very early stage. Please feel free to report any bugs and improvements!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8790d703",
   "metadata": {},
   "source": [
    "## Functions\n",
    "This is the \"backend\" and needs only to be ran, but not modified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2387e405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_files(dir_path,ext=\".txt\"): #edit to be JSON so that cleaned file from nanopreapre can be read! \n",
    "    \"\"\"Gets files from one directory and stores them into a list.\"\"\"\n",
    "    files_list = [] #list of file names\n",
    "    files_dir = [] #list of file directories\n",
    "    for root, dirs, files in os.walk(dir_path):\n",
    "        for name in files:\n",
    "        #get only txt files but exclude position.txt\n",
    "            if ext==\".txt\":\n",
    "                if name.endswith(ext) and not name.endswith('position.txt'):\n",
    "                    files_list.append(name)\n",
    "                    files_dir.append(os.path.join(root, name))\n",
    "            else:\n",
    "            #for other extensions, do not exclude files\n",
    "                if name.endswith(ext):\n",
    "                    files_list.append(name)\n",
    "                    files_dir.append(os.path.join(root, name))\n",
    "    return files_list, files_dir\n",
    "\n",
    "def read_file(f): \n",
    "    \"\"\"\n",
    "    Reads one .txt file \n",
    "    \"\"\"\n",
    "    with open(f, encoding='utf-8', errors='ignore') as dynamic:\n",
    "        stopLine = 'Time (s)'\n",
    "        numeric = False\n",
    "        data = []\n",
    "        for riga in dynamic:\n",
    "            if numeric is False:\n",
    "                if riga[0:len(stopLine)] == stopLine:\n",
    "                    numeric = True\n",
    "            else:\n",
    "                line = riga.strip().replace(',', '.').split('\\t')\n",
    "                # Time (s) Load (uN) Indentation (nm) Cantilever (nm) Piezo (nm) Auxiliary\n",
    "                # skip  #5 auxiliary if present\n",
    "                data.append([float(line[0]), float(line[1])*1000.0, float(line[2]),\n",
    "                            float(line[3]), float(line[4])])\n",
    "        data = np.array(data)\n",
    "    return data\n",
    "\n",
    "def getMedCurve(xar, yar,loose=True, threshold=3, error=False):\n",
    "    \"\"\"\n",
    "    Takes repeated nummerical data (replicates stored in a multi dimensional list) \n",
    "    and computes the average and error. Useful for displaying \"average\" plots\n",
    "    with error bands.\n",
    "    This function was taken from the following github repo (https://github.com/CellMechLab/nanoindentation),\n",
    "    author Prof Massimo Vassalli at the Cellular Mechanobiology Lab, University of Glasgow.\n",
    "    \"\"\"\n",
    "    if loose is False:\n",
    "        xmin = -np.inf\n",
    "        xmax = np.inf\n",
    "        deltax = 0\n",
    "        nonecount = 0\n",
    "        for x in xar:\n",
    "            if x is not None and np.min(x) is not None:\n",
    "                xmin = np.max([xmin, np.min(x)])\n",
    "                xmax = np.min([xmax, np.max(x)])\n",
    "                deltax += ((np.max(x)-np.min(x))/(len(x)-1))\n",
    "            else:\n",
    "                nonecount += 1\n",
    "        deltax /= (len(xar)-nonecount)\n",
    "        xnew = np.linspace(xmin, xmax, int((xmax-xmin)/(deltax)))\n",
    "        ynew = np.zeros(len(xnew))\n",
    "        for i in range(len(xar)):\n",
    "            if xar[i] is not None and np.min(xar[i]) is not None:\n",
    "                ycur = np.interp(xnew, xar[i], yar[i])\n",
    "                ynew += ycur\n",
    "        ynew /= (len(xar)-nonecount)\n",
    "    else:\n",
    "        xmin = np.inf\n",
    "        xmax = -np.inf\n",
    "        deltax = 0\n",
    "        for x in xar:\n",
    "            try:\n",
    "                xmin = np.min([xmin, np.min(x)])\n",
    "                xmax = np.max([xmax, np.max(x)])\n",
    "                deltax += ((np.max(x) - np.min(x)) / (len(x) - 1))\n",
    "            except TypeError:\n",
    "                return\n",
    "        deltax /= len(xar)\n",
    "        xnewall = np.linspace(xmin, xmax, int((xmax - xmin) / deltax))\n",
    "        ynewall = np.zeros(len(xnewall))\n",
    "        count = np.zeros(len(xnewall))\n",
    "        ys = np.zeros([len(xnewall), len(xar)])\n",
    "        for i in range(len(xar)):\n",
    "            imin = np.argmin((xnewall - np.min(xar[i])) ** 2)  # +1\n",
    "            imax = np.argmin((xnewall - np.max(xar[i])) ** 2)  # -1\n",
    "            ycur = np.interp(xnewall[imin:imax], xar[i], yar[i])\n",
    "            ynewall[imin:imax] += ycur\n",
    "            count[imin:imax] += 1\n",
    "            for j in range(imin, imax):\n",
    "                ys[j][i] = ycur[j-imin]\n",
    "        cc = count >= threshold\n",
    "        xnew = xnewall[cc]\n",
    "        ynew = ynewall[cc] / count[cc]\n",
    "        yerrs_new = ys[cc]\n",
    "        yerr = []\n",
    "        for j in range(len(yerrs_new)):\n",
    "            squr_sum = 0\n",
    "            num = 0\n",
    "            std = 0\n",
    "            for i in range(0, len(yerrs_new[j])):\n",
    "                if yerrs_new[j][i] != 0:\n",
    "                    squr_sum += (yerrs_new[j][i] - ynew[j]) ** 2\n",
    "                    num += 1\n",
    "            if num > 0:\n",
    "                std = np.sqrt(squr_sum / num)\n",
    "            yerr.append(std)\n",
    "        yerr = np.asarray(yerr)\n",
    "    if error == False:\n",
    "        return xnew[:-1], ynew[:-1]\n",
    "    elif error == True:\n",
    "        return xnew[:-1], ynew[:-1], yerr[:-1]\n",
    "\n",
    "def get_times_DMA(f):\n",
    "    \"\"\"\n",
    "    Returns touple of arrays with start and end times of DMA sweeps\n",
    "    \"\"\"\n",
    "    with open(f, encoding='utf-8', errors='ignore') as dynamic:\n",
    "        target_start = 'DMA absolute start times (s)'\n",
    "        target_end = 'DMA absolute end times (s)'\n",
    "        for riga in dynamic:\n",
    "            if riga[0:len(target_start)]==target_start:\n",
    "                good_start = riga[len(target_start):].strip()\n",
    "                better_start = list(map(float, good_start.split(',')))\n",
    "            if riga[0:len(target_end)]==target_end:\n",
    "                good_end = riga[len(target_end):].strip()\n",
    "                better_end = list(map(float, good_end.split(',')))\n",
    "    return better_start, better_end\n",
    "\n",
    "def ft_relax(g, t, g_0=1, g_dot_inf=0, N_f=100, interpolate=True, oversampling=10):\n",
    "    \"\"\" Calculates the Fourier transform of numeric data.\n",
    "\n",
    "    Takes any numeric time-dependent function g(t) that vanishes fot t<0,\n",
    "    sampled at finite points [g_k,t_k] with k=1...N, and returns its \n",
    "    Fourier transform g(omega), together with the frequency range omega \n",
    "    defined from 1/t_max to 1/t_min. For details on the numerical procedure,\n",
    "    refer to Tassieri et al., 2016 (https://doi.org/10.1122/1.4953443).\n",
    "\n",
    "    Parameters\n",
    "    ---------\n",
    "    g : array \n",
    "        measured time-dependent variable.\n",
    "    t : array \n",
    "        time array. \n",
    "    g_0: \n",
    "        value of g at time euqal 0. Can be taken as g[0].\n",
    "    g_dot_inf:\n",
    "        value of the time derivative of g at time equal infinity. Can be taken as 0.\n",
    "    N_f: int\n",
    "        frequency samples.\n",
    "    interpolate: bool\n",
    "        if True, data is interpolated with a cubic spline and re-sampled in log-space.\n",
    "    oversampling: int\n",
    "        factor by which the length of the time array is increased for oversampling in log-space.\n",
    "    \"\"\"\n",
    "    g = np.array(g)\n",
    "    t = np.array(t)\n",
    "\n",
    "    if interpolate is True:\n",
    "        gi = interp1d(t, g, kind='cubic', fill_value='extrapolate')\n",
    "        t_new = np.logspace(min(np.log10(t)), max(np.log10(t)), len(\n",
    "            t)*oversampling)  # re-sample t in log space\n",
    "        g = gi(t_new)  # get new g(t) taken at log-space sampled t\n",
    "        t = t_new\n",
    "    i = complex(0, 1)\n",
    "    min_omega = 1/max(t)\n",
    "    max_omega = 1/min(t)\n",
    "    N_t = len(t)\n",
    "    omega = np.logspace(np.log10(min_omega), np.log10(max_omega), N_f)\n",
    "    zero = i*omega*g_0 + (1-np.exp(-i*omega*t[1]))*((g[1]-g_0)/t[1])\\\n",
    "        + g_dot_inf*np.exp(-i*omega*t[N_t-1])\n",
    "    res = np.zeros(len(omega), dtype=complex)\n",
    "    for w_i, w in enumerate(omega):\n",
    "        after = 0\n",
    "        for k in range(2, N_t):\n",
    "            after += ((g[k] - g[k-1]) / (t[k] - t[k-1])) * (np.exp(-i * w *\n",
    "                                                                   t[k-1])-np.exp(-i * w * t[k]))\n",
    "        res[w_i] = (zero[w_i]+after)\n",
    "    return omega, ((res)/(i*omega)**2)  # is omega Hz or rad/s\n",
    "\n",
    "def linear(x,a,b):\n",
    "    return a*x +b\n",
    "\n",
    "def sls_model(x,E_1,E_2,tau):\n",
    "    \"standard linear solid model (prony).\"\n",
    "    E_t = E_2*np.exp(-x/tau)  #Relaxation modulus  \n",
    "    return ((4/3 * np.sqrt(R)) * ((E_1+E_t)/(1-nu**2)) * delta_0**(3/2))\n",
    "\n",
    "def prony_model(x,E_1,E_2,E_3,tau2,tau3):\n",
    "    \"standard linear solid model (prony).\"\n",
    "    E_t = E_2*np.exp(-x/tau2) + E_3*np.exp(-x/tau3) #Relaxation modulus (Prony Series) \n",
    "    return ((4/3 * np.sqrt(R)) * ((E_1+E_t)/(1-nu**2)) * delta_0**(3/2))\n",
    "\n",
    "def do_fit(model,xdata,ydata,guess=None):\n",
    "    \"\"\"Fits data based on a given model.\"\"\"\n",
    "    xdata=np.asarray(xdata)\n",
    "    ydata=np.asarray(ydata)\n",
    "    popt, pcov = curve_fit(model,xdata,ydata,maxfev=10000,p0=guess)\n",
    "    xdata=np.linspace(min(xdata),max(xdata),1000)\n",
    "    return [xdata, model(xdata,*popt)]\n",
    "\n",
    "def linear_detrend(tdata,fdata):\n",
    "    #Isolate drifted signal\n",
    "    start = np.argmin((tdata-10.0)**2) #end of fast relaxation\n",
    "    end = np.argmin((tdata-55.0)**2) #end of signal \n",
    "    fdata_drift = fdata[start:end]\n",
    "    tdata_drift = tdata[start:end]\n",
    "    popt,pcov=curve_fit(linear,tdata_drift,fdata_drift)\n",
    "    time_all = np.linspace(min(tdata),max(tdata),len(tdata))\n",
    "    fmodel = linear(time_all,*popt)\n",
    "    de_drifted = fdata-fmodel\n",
    "    return de_drifted,popt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be4251",
   "metadata": {},
   "source": [
    "## Input Data \n",
    "Below, input the directory to the cleaned JSON file originating from NanoPrepare. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5282bf19",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "dirw=widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Please enter the files directory',\n",
    "    description='Directory:',\n",
    "    disabled=False\n",
    ")\n",
    "display(dirw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d268de",
   "metadata": {},
   "source": [
    "## Screening \n",
    "The plot below serves to *select* the thresholds for screening and aligning curves. This section is used only to selct the threshold; the actual data is thresholded in the next section (**Adjusting**) if the \"Threshold\" checkbox is checked. The data can be thresholded based on the following thresholds: \n",
    "\n",
    "1. tmin (s): the time under which the maximum force should occur. Any curve whose maximum force occurs after this time is discarded from the analysis. \n",
    "2. tmax (s): the maximum time one wants to display and analyse the data for. This is used to essentially remove the ramping down of the stress relaxation curve. Alla data points after this time are discarded.\n",
    "3. fmin (uN): the minimum acceptable value for the maximum (peak) force. Any curve whose maximum force is smaller than fmin will be discarded.\n",
    "4. fmax (uN): the maximum acceptable value for the maximum (peak) force. Any curve whose maximum force is greater than fmax will be discarded.\n",
    "\n",
    "tip: adjust the sliders by typing the approximate value for the variable in the box next to the slider and click enter on your keyboard. Just sliding will update the plot for each value the slider passes through, resulting in a laggy visual update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45079f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(dirw.value)\n",
    "data = json.load(f)\n",
    "def first_plot(tmin=0.5,tmax=30.0,fmin=0.0,fmax=50.0):\n",
    "    fig,ax=plt.subplots(1,2,figsize=(8,3))\n",
    "    tall = []\n",
    "    fall = []\n",
    "    for i in range(len(data['curves'])):\n",
    "        raw_time = np.array(data['curves'][i]['raw_data']['raw_time'])\n",
    "        raw_force = np.array(data['curves'][i]['raw_data']['raw_force'])\n",
    "        for_force = np.array(data['curves'][i]['data']['F']) #for = forward segment\n",
    "        for_Z = np.array(data['curves'][i]['data']['Z'])\n",
    "        \n",
    "        #Offset force-time curves \n",
    "        off = raw_force[0] #first point\n",
    "        #if forst point is negative, align\n",
    "        if off <0: \n",
    "            raw_force = raw_force-off\n",
    "        else:\n",
    "            raw_force = raw_force\n",
    "        \n",
    "        #Offset F-z forward curves\n",
    "        for_off = for_force[0]\n",
    "        \n",
    "        if for_off <0: \n",
    "            for_force = for_force-for_off\n",
    "        else:\n",
    "            for_force= for_force\n",
    "    \n",
    "        ax[0].plot(raw_time,raw_force,alpha=1,lw=0.1,c='k')\n",
    "        ax[1].plot(for_Z,for_force, lw=0.1,c='k')\n",
    "        ax[0].axhline(fmin,c=\"salmon\",lw=1)\n",
    "        ax[0].axhline(fmax,c=\"salmon\",lw=1)\n",
    "        ax[0].axvline(tmax,lw=1)\n",
    "        ax[0].axvline(tmin,lw=1)\n",
    "    ax[0].set_xlabel('time (s)')\n",
    "    ax[0].set_ylabel('force (uN)')\n",
    "    ax[1].set_ylabel('force (N)')\n",
    "    ax[1].set_xlabel('Z (m)')\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "plot1w=widgets.interactive(first_plot,tmin=(0.0,50.0,0.5), tmax=(0.0,100.0,0.5),fmin=(0.0,100.0,0.1),fmax=(0.0,1500.0,0.1))\n",
    "display(plot1w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5000cc8",
   "metadata": {},
   "source": [
    "## Adjusting\n",
    "Now click the \"Threshold\" checkbox if you want to apply the above-specified thresholds to the data.\n",
    "\n",
    "Given the above specified thresholds, the code below finds the maximum force and corresponding time and aligns this value to 0. All curves should now start from t=0. Note that the maximum time displayed will be different from the one selected above as curves are shifted by the time at which the maximum force occurs (however relative time interval is preserved)!\n",
    "\n",
    "In the end, the average curve is plotted (red) on top of the individual curves (black)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac9c9a4-d249-4f4f-acda-4e631b336451",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting plots parameters\n",
    "%matplotlib qt\n",
    "plt.rcParams['figure.dpi'] = 300\n",
    "plt.rcParams['font.size']= 8\n",
    "plt.style.use(\"seaborn-colorblind\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cfc22c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholdw=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Threshold data',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(thresholdw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf7ccbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Widget parameters (Global thresholds)\n",
    "t_min=plot1w.kwargs[\"tmin\"] #s #time under which max force should occur\n",
    "t_max=plot1w.kwargs[\"tmax\"] #s #max time to display and analyse data for\n",
    "f_min=plot1w.kwargs[\"fmin\"] #The minium acceptable value for the max force (uN)\n",
    "f_max = plot1w.kwargs[\"fmax\"]#The maximum acceptable value for the max force (uN)\n",
    "\n",
    "tall = []\n",
    "fall = []\n",
    "fnormall=[]\n",
    "fig,ax = plt.subplots(1,1,figsize=(4,2))\n",
    "for i in range(len(data['curves'])):\n",
    "    raw_time = np.array(data['curves'][i]['raw_data']['raw_time'])\n",
    "    raw_force = np.array(data['curves'][i]['raw_data']['raw_force'])\n",
    "    for_force = np.array(data['curves'][i]['data']['F']) #for = forward segment\n",
    "    for_Z = np.array(data['curves'][i]['data']['Z'])\n",
    "    #Offset force-time curves \n",
    "    off = raw_force[0] #first point\n",
    "    #if forst point is negative, align\n",
    "    if off <0: \n",
    "        raw_force = raw_force-off\n",
    "    else:\n",
    "        raw_force = raw_force\n",
    "    #Clean data based on user-selected thresholds\n",
    "    #NB: to be applied on raw data \n",
    "    fmax = max(raw_force)\n",
    "    imaxf = np.argmin((raw_force-fmax)**2)\n",
    "    if thresholdw.value is True:\n",
    "        if (fmax > f_max) or (fmax < f_min) or raw_time[imaxf] > t_min:\n",
    "            continue \n",
    "    #Align data to 0 and slice to user-selcted max time\n",
    "    itmax =np.argmin((raw_time-t_max)**2)\n",
    "    t=raw_time[imaxf:itmax]-raw_time[imaxf]\n",
    "    f=raw_force[imaxf:itmax]\n",
    "    fnorm=f/max(f) #normalised force\n",
    "    tall.append(t)\n",
    "    fall.append(f)\n",
    "    fnormall.append(fnorm)\n",
    "ax.set_title(\"Average curve\")\n",
    "ax.set_xlabel('Time (s)')\n",
    "ax.set_ylabel('Force (uN)')\n",
    "\n",
    "#Find and plot average curve\n",
    "t_av,f_av,f_err=getMedCurve(tall,fall,error=True) #average curve\n",
    "_,_,f_err_norm=getMedCurve(tall,fnormall,error=True) #average normalised curve\n",
    "discard = 30\n",
    "t_av = t_av[:-discard]\n",
    "f_av = f_av[:-discard]\n",
    "f_err = f_err[:-discard]\n",
    "f_err_norm=f_err_norm[:-discard]\n",
    "ax.errorbar(t_av,f_av,c='tomato',lw=1,ls='-',alpha=1) \n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f3ef6e-0c89-4fa5-a075-9d76a6c46835",
   "metadata": {},
   "source": [
    "If the average curve has an upwards trend (temperature drift), detrend data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d203b13-edd9-4d27-9b67-2012094a9904",
   "metadata": {},
   "outputs": [],
   "source": [
    "detrendw=widgets.Checkbox(\n",
    "    value=False,\n",
    "    description='Detrend data',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "display(detrendw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b459afe-d583-4857-91a1-694c936a7694",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,axs = plt.subplots(1,2,figsize=(6,1.5))\n",
    "if detrendw.value is True: \n",
    "    #average curve (absolute)\n",
    "    f_av_detrended,optd = linear_detrend(t_av,f_av) \n",
    "    f_av_detrended = f_av_detrended+optd[1] #add back y intercept for correct f scaling\n",
    "    f_av = f_av_detrended\n",
    "    #error (absolute)\n",
    "    f_err_detrended,optd = linear_detrend(t_av,f_err) \n",
    "    f_err_detrended = f_err_detrended+optd[1]\n",
    "    f_err=f_err_detrended\n",
    "    #error (from normalised curves)\n",
    "    f_err_detrended_norm,optd = linear_detrend(t_av,f_err_norm) \n",
    "    f_err_detrended_norm = f_err_detrended_norm+optd[1]\n",
    "    f_err_norm=f_err_detrended_norm\n",
    "    \n",
    "axs[0].plot(t_av,f_av)\n",
    "axs[1].plot(t_av,f_av/max(f_av))\n",
    "axs[0].set_title(\"Data\")\n",
    "axs[1].set_title(\"Normalised Data\")\n",
    "axs[0].set_xlabel(\"Time (s)\")\n",
    "axs[1].set_xlabel(\"Time (s)\")\n",
    "axs[0].set_ylabel(\"Force (uN)\")\n",
    "axs[1].set_ylabel(\"Norm. Force\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b885c35-6b94-4e4a-bcde-5ee7e83688d4",
   "metadata": {},
   "source": [
    "## Fitting data\n",
    "Fit average curve with relaxation model. This can be a Standard linear solid (SLS) or Prony series; i.e. a generalised maxwell model with two relaxation times, see for example https://pubs.rsc.org/en/content/articlelanding/2020/sm/c9sm01020c or https://pubs.rsc.org/en/content/articlelanding/2020/bm/c9bm01339c).\n",
    "The SLS model has 3 fitting parameters ($E_1$, the long term elastic modulus - $E_2$, the relaxation modulus - and its associated time constant, $\\tau_2$).\n",
    "The prony series model has 4 fitting parameters ($E_1$, the long term elastic modulus - $E_2$ and $E_3$, the relaxation moduli - and their associated time constants, $\\tau_2$ and $\\tau_3$).\n",
    "The user needs to enter the Poisson's ratio, the tip radius and the approximate constant indentation depth; as Hertzian contact is still assumed. After, the user is prompted with what model to fit the average curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3012701f-4a00-4084-bab3-b95c6ecf2e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "poisson = widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    description='Poisson\\'s:',\n",
    "    disabled=False\n",
    ")\n",
    "display(poisson)\n",
    "\n",
    "radius = widgets.BoundedFloatText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=250,\n",
    "    step=0.5,\n",
    "    description='$R$ (um):',\n",
    "    disabled=False\n",
    ")\n",
    "display(radius)\n",
    "\n",
    "ind_0 = widgets.BoundedFloatText(\n",
    "    value=3,\n",
    "    min=1,\n",
    "    max=250,\n",
    "    step=0.5,\n",
    "    description='$\\delta_0$ (um):',\n",
    "    disabled=False\n",
    ")\n",
    "display(ind_0)\n",
    "\n",
    "chosen_model = widgets.Dropdown(\n",
    "    options=['SLS', 'Prony'],\n",
    "    value='Prony',\n",
    "    description='Model:',\n",
    "    disabled=False,\n",
    ")\n",
    "display(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675cd860-c71c-4681-bd45-0c427439b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "nu = poisson.value\n",
    "R = radius.value\n",
    "delta_0 = ind_0.value\n",
    "fig,ax=plt.subplots(1,1,figsize=(4,2))\n",
    "if chosen_model.value==\"Prony\":\n",
    "    model_name = \"Prony\"\n",
    "    seed = [f_av[-1],(f_av[-1]+f_av[0]),(f_av[-1]+f_av[0]),0.1,10.0]\n",
    "    popt,pcov = curve_fit(prony_model,t_av,f_av,sigma=f_err,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    ax.plot(t_av,f_av,lw=4,label=\"Raw data\")\n",
    "    ax.plot(t_av,prony_model(t_av,*popt),'--',c='r',lw=2,label=model_name +\" Model\")\n",
    "    norm_model=prony_model(t_av,*popt)/max(f_av)\n",
    "if chosen_model.value==\"SLS\":\n",
    "    model_name = \"SLS\"\n",
    "    seed = [f_av[-1],(f_av[-1]+f_av[0]),10.0]\n",
    "    popt,pcov = curve_fit(sls_model,t_av,f_av,sigma=f_err,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"s\n",
    "    perr = np.sqrt(np.diag(pcov))\n",
    "    ax.plot(t_av,f_av,lw=4,label=\"Raw data\")\n",
    "    ax.plot(t_av,sls_model(t_av,*popt),'--',c='r',lw=2,label=model_name+\" Model\")\n",
    "    norm_model=sls_model(t_av,*popt)/max(f_av)\n",
    "plt.legend()\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Force (uN)\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ced0ad-7b73-4467-8a01-ea89ca54e19c",
   "metadata": {},
   "source": [
    "Final plot to save for representative purposes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56d4589-c84c-4808-b25d-efb34300b8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,1,figsize=(3.5,2))\n",
    "f_av_norm=f_av/max(f_av)\n",
    "ax.plot(t_av,f_av_norm,label=\"Average Data\")\n",
    "ax.fill_between(t_av,f_av_norm-0.5*f_err_norm,f_av_norm+0.5*f_err_norm,alpha=0.3,label=\"1SD\")\n",
    "ax.plot(t_av,norm_model,'--',c='r',lw=1,label=model_name+\" Model\")\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Norm. Force\")\n",
    "plt.legend()\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc4ba5a-04fb-410f-ad52-08cfe77ae7f0",
   "metadata": {},
   "source": [
    " ## Saving data\n",
    " The cell below saves the data from the average curve in a .tsv file, together with the fitted model and best model parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be82057",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "savingfolderw=widgets.Text(\n",
    "    placeholder='Output folder',\n",
    "    disabled=False\n",
    ")\n",
    "boxw1=widgets.HBox([widgets.Label(value=\"Output Folder\"), savingfolderw])\n",
    "display(boxw1)\n",
    "\n",
    "samplenamew=widgets.Text(\n",
    "    placeholder='Please enter the sample name',\n",
    "    disabled=False\n",
    ")\n",
    "boxw2=widgets.HBox([widgets.Label(value=\"Sample Name\"), samplenamew])\n",
    "display(boxw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d798b5e1-a51b-43bd-a0d2-6f59885456f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fname=savingfolderw.value+\"/\"+samplenamew.value +\".tsv\"\n",
    "with open(fname,\"w\") as f: \n",
    "    f.write(\"Exported stress relaxation analysis \\n\")\n",
    "    f.write(\"Sample Name: {} \\n\".format(samplenamew.value))\n",
    "    f.write(\"Fitted model: {} \\n\".format(model_name))\n",
    "    if model_name == \"Prony\":\n",
    "        f.write(\"Model tau_2 (s) {} pm {} \\n\".format(popt[3],perr[3]))\n",
    "        f.write(\"Model tau_3 (s) {} pm {} \\n\".format(popt[4],perr[4]))\n",
    "    if model_name ==\"SLS\":\n",
    "        f.write(\"Model tau_1 (s) {} pm {} \\n\".format(popt[2],perr[2]))\n",
    "    f.write('Avg time [s] \\t Avg Norm Force \\t Error Force \\t Normalised Model \\n')\n",
    "    for x in zip(*[t_av,f_av_norm,f_err_norm,norm_model]):\n",
    "                 f.write(\"{0}\\t{1}\\t{2}\\t{3}\\n\".format(*x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee63f2d1",
   "metadata": {},
   "source": [
    "## Relaxation time\n",
    "Below, you can enter the stress value for which you wish to calculate the relaxation time. For example, 0.5 means calculating the time for which the stress relaxes to half of its original value. The average curve is used for this calculation as single curves are too noisy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de9fa3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "relaxation_timew=widgets.BoundedFloatText(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.0,\n",
    "    step=0.1,\n",
    "    disabled=False\n",
    ")\n",
    "boxw=widgets.HBox([widgets.Label(value=\"Enter stress value for which relaxation time is calculated:\"), relaxation_timew])\n",
    "display(boxw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract time at which force reaches % of original value (specified above)\n",
    "F_TARGET=relaxation_timew.value*(max(f_av_norm)) \n",
    "i_fclose = np.argmin((f_av_norm-F_TARGET)**2) \n",
    "t_target=t_av[i_fclose]\n",
    "print(f\"The time for which the stress relaxes to {(relaxation_timew.value*100.0)}% of the original value is {t_target} s!\")\n",
    "\n",
    "def plot_average(): \n",
    "    plt.plot(t_av,f_av_norm,zorder=-1)\n",
    "    plt.scatter(t_target,f_av_norm[i_fclose],c='red',zorder=1,alpha=0.5)\n",
    "    plt.xlabel('Time (s)')\n",
    "    plt.ylabel('Normalised force')\n",
    "    plt.show()\n",
    "    \n",
    "widgets.interactive(plot_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b36a66fe",
   "metadata": {},
   "source": [
    "# Fitting single curves with given model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc2fa81-a21a-4c56-8458-cd5e19a50e66",
   "metadata": {},
   "source": [
    "Below, single $F-t$ curves are fitted using a stress relaxation model (Standard linear solid (SLS) or Prony series; i.e. a generalised maxwell model with two relaxation times, see for example https://pubs.rsc.org/en/content/articlelanding/2020/sm/c9sm01020c or https://pubs.rsc.org/en/content/articlelanding/2020/bm/c9bm01339c).\n",
    "The SLS model has 3 fitting parameters ($E_1$, the long term elastic modulus - $E_2$, the relaxation modulus - and its associated time constant, $\\tau_2$).\n",
    "The prony series model has 4 fitting parameters ($E_1$, the long term elastic modulus - $E_2$ and $E_3$, the relaxation moduli - and their associated time constants, $\\tau_2$ and $\\tau_3$).\n",
    "The user needs to enter the Poisson's ratio, the tip radius and the approximate constant indentation depth; as Hertzian contact is still assumed. After, the user is prompted with what model to fit the single curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fb88fe-6d1c-4916-a42b-14653df4b7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# poisson = widgets.BoundedFloatText(\n",
    "#     value=0.5,\n",
    "#     min=0,\n",
    "#     max=1.0,\n",
    "#     step=0.1,\n",
    "#     description='Poisson\\'s:',\n",
    "#     disabled=False\n",
    "# )\n",
    "# display(poisson)\n",
    "\n",
    "# radius = widgets.BoundedFloatText(\n",
    "#     value=3,\n",
    "#     min=1,\n",
    "#     max=250,\n",
    "#     step=0.5,\n",
    "#     description='$R$ (um):',\n",
    "#     disabled=False\n",
    "# )\n",
    "# display(radius)\n",
    "\n",
    "# ind_0 = widgets.BoundedFloatText(\n",
    "#     value=3,\n",
    "#     min=1,\n",
    "#     max=250,\n",
    "#     step=0.5,\n",
    "#     description='$\\delta_0$ (um):',\n",
    "#     disabled=False\n",
    "# )\n",
    "# display(ind_0)\n",
    "\n",
    "# chosen_model = widgets.Dropdown(\n",
    "#     options=['SLS', 'Prony'],\n",
    "#     value='Prony',\n",
    "#     description='Model:',\n",
    "#     disabled=False,\n",
    "# )\n",
    "# display(chosen_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d7a320-3d24-479c-8363-cd6dfb6ebdce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Widget parameters (Global thresholds)\n",
    "# t_min=plot1w.kwargs[\"tmin\"] #s #time under which max force should occur\n",
    "# t_max=plot1w.kwargs[\"tmax\"] #s #max time to display and analyse data for\n",
    "# f_min=plot1w.kwargs[\"fmin\"] #The minium acceptable value for the max force (uN)\n",
    "# f_max = plot1w.kwargs[\"fmax\"]#The maximum acceptable value for the max force (uN)\n",
    "\n",
    "# #Constants for fitting procedure\n",
    "# nu = poisson.value\n",
    "# R = radius.value\n",
    "# delta_0 = ind_0.value\n",
    "# tau2_all = [] # to append in for loo\n",
    "# tau3_all = [] # to append in for loop\n",
    "# fig,ax = plt.subplots(1,1,figsize=(4,2))\n",
    "# for i in range(len(data['curves'])):\n",
    "#     raw_time = np.array(data['curves'][i]['raw_data']['raw_time'])\n",
    "#     raw_force = np.array(data['curves'][i]['raw_data']['raw_force']) \n",
    "#     for_force = np.array(data['curves'][i]['data']['F']) #for = forward segment\n",
    "#     for_Z = np.array(data['curves'][i]['data']['Z'])\n",
    "#     #Offset force-time curves \n",
    "#     off = raw_force[0] #first point\n",
    "#     #if forst point is negative, align\n",
    "#     if off <0: \n",
    "#         raw_force = raw_force-off\n",
    "#     else:\n",
    "#         raw_force = raw_force\n",
    "#     #Clean data based on user-selected thresholds\n",
    "#     #NB: to be applied on raw data \n",
    "#     fmax = max(raw_force)\n",
    "#     imaxf = np.argmin((raw_force-fmax)**2)\n",
    "        \n",
    "#     if thresholdw.value is True:\n",
    "#         if (fmax > f_max) or (fmax < f_min) or raw_time[imaxf] > t_min:\n",
    "#             continue   \n",
    "#     #Align data to 0 and slice to user-selcted max time\n",
    "#     itmax =np.argmin((raw_time-t_max)**2)\n",
    "#     t=raw_time[imaxf:itmax]-raw_time[imaxf] #s\n",
    "#     t_mod = np.linspace(min(t),max(t),1000)\n",
    "#     f=raw_force[imaxf:itmax] #uN\n",
    "#     #Smooth data with Sav-gol filter \n",
    "#     win = 101\n",
    "#     f=savgol_filter(f,win,3)\n",
    "#     f=f[win:-win]\n",
    "#     t=t[win:-win]\n",
    "    \n",
    "#     #Filter low-frequency noise\n",
    "#     # fs = 1/t[1]-t[0]\n",
    "#     # filt = butter(5, 0.0005, fs=fs,btype='lowpass', output='sos')\n",
    "#     # f = sosfiltfilt(filt, f)\n",
    "    \n",
    "#     if chosen_model.value==\"Prony\":\n",
    "#         try:\n",
    "#             seed = [f[-1],(f[-1]+f[0]),(f[-1]+f[0]),0.1,10.0]\n",
    "#             popt,pcov = curve_fit(prony_model,t,f,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"\n",
    "#             residuals = f - prony_model(t,*popt)\n",
    "#             plt.plot(t_mod,prony_model(t_mod,*popt),'--',c='r',lw=0.5)\n",
    "#         except:\n",
    "#             continue\n",
    "    \n",
    "#     if chosen_model.value==\"SLS\":\n",
    "#         try:\n",
    "#             seed = [f[-1],(f[-1]+f[0]),10.0]\n",
    "#             popt,pcov = curve_fit(sls_model,t,f,p0=seed,maxfev=100000) #method='trf', #loss=\"soft_l1\"s\n",
    "#             residuals = f - sls_model(t,*popt)\n",
    "#             plt.plot(t_mod,sls_model(t_mod,*popt),'--',c='r',lw=0.1)\n",
    "#         except:\n",
    "#             continue\n",
    "            \n",
    "#     ss_res = np.sum(residuals**2)\n",
    "#     ss_tot = np.sum((f-np.mean(f))**2)\n",
    "#     R_squared = 1 - (ss_res / ss_tot)\n",
    "#     if R_squared > 0.8: #get fits where R**2 > 0.8\n",
    "#         tau2_all.append(popt[3])\n",
    "#         tau3_all.append(popt[4])\n",
    "#     plt.plot(t,f,'-',c=\"k\",alpha=0.5,lw=1)\n",
    "#     ax.set_xlabel(\"Time (s)\")\n",
    "#     ax.set_ylabel(\"Force (uN)\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b307d32-f61e-40eb-8d41-982e188331bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# savingfolderw=widgets.Text(\n",
    "#     placeholder='Output folder',\n",
    "#     disabled=False\n",
    "# )\n",
    "# boxw1=widgets.HBox([widgets.Label(value=\"Output Folder\"), savingfolderw])\n",
    "# display(boxw1)\n",
    "\n",
    "# samplenamew=widgets.Text(\n",
    "#     placeholder='Please enter the sample name',\n",
    "#     disabled=False\n",
    "# )\n",
    "# boxw2=widgets.HBox([widgets.Label(value=\"Sample Name\"), samplenamew])\n",
    "# display(boxw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd9967-a654-4366-b49e-ff5d3455addf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_name=samplenamew.value\n",
    "# sample_name = sample_name + \".csv\"\n",
    "# data={\"tau_2 (s)\": tau2_all, \"tau_3 (s)\": tau3_all}\n",
    "# df=pd.DataFrame(data)\n",
    "# df.to_csv(os.path.join(savingfolderw.value,sample_name),index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "84b25d0415491253f03f694f57af598572a98abd3b82a154133d6b656667b885"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
